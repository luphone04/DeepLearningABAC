{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15a09757-e74a-4d31-b01f-142206781d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load MNIST dataset from TensorFlow/Keras\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the input images to the range [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the data to include the channel dimension (required for CNNs)\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoded vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)  # 10 classes for digits 0-9\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07900eba-0f98-4f64-b7e9-5edb3e6b5ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 28, 28, 1)\n",
      "Train labels shape: (10000, 28, 28, 1)\n",
      "Test images shape: (60000, 10)\n",
      "Test labels shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train images shape: {X_train.shape}')\n",
    "print(f'Train labels shape: {X_test.shape}')\n",
    "print(f'Test images shape: {y_train.shape}')\n",
    "print(f'Test labels shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71867d6d-c26a-46e3-be29-f36826d680e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (60000, 28, 28, 1)\n",
      "Shape of y_train: (60000, 10)\n",
      "Shape of X_test: (10000, 28, 28, 1)\n",
      "Shape of y_test: (10000, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.2123 - accuracy: 0.9357 - val_loss: 0.0633 - val_accuracy: 0.9813\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 0.0516 - val_accuracy: 0.9846\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0396 - accuracy: 0.9872 - val_loss: 0.0412 - val_accuracy: 0.9883\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0472 - val_accuracy: 0.9855\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0424 - val_accuracy: 0.9879\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0380 - val_accuracy: 0.9902\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.0389 - val_accuracy: 0.9897\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0453 - val_accuracy: 0.9896\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.0473 - val_accuracy: 0.9878\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.0347 - val_accuracy: 0.9912\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0492 - val_accuracy: 0.9894\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0471 - val_accuracy: 0.9884\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0537 - val_accuracy: 0.9879\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0532 - val_accuracy: 0.9887\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0508 - val_accuracy: 0.9902\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.0486 - val_accuracy: 0.9898\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0509 - val_accuracy: 0.9898\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0485 - val_accuracy: 0.9903\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0406 - val_accuracy: 0.9918\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0478 - val_accuracy: 0.9908\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9916\n",
      "Test accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the input images to the range [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the data to include the channel dimension (required for CNNs)\n",
    "# Assuming images are 28x28 pixels\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Verify the shape of the data\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# First convolutional layer\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Third convolutional layer\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Flatten the output from the convolutional layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Output layer with softmax activation for classification\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d76fe66-276e-447e-968a-522c54f2a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b2d1fc-036a-4998-b801-c6a831a13504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 20:57:44.332529: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-25 20:57:47.652417: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture coordinates: (5, 35, 211, 241)\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Capture coordinates: (287, 65, 493, 271)\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tkinter as tk\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('mnist.h5')  # Ensure this matches the saved model\n",
    "\n",
    "def predict_digit(img, save_path='processed_image.png'):\n",
    "    # Resize image to 28x28 pixels\n",
    "    img = img.resize((28, 28))\n",
    "    # Convert RGB to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    # Normalize the image\n",
    "    img = img / 255.0\n",
    "    # Reshape for model input\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "\n",
    "    # Save the processed image for inspection\n",
    "    plt.imsave(save_path, img.reshape(28, 28), cmap='gray')\n",
    "\n",
    "    # Predict the class\n",
    "    res = model.predict([img])[0]\n",
    "    return np.argmax(res), max(res)\n",
    "\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "        self.x = self.y = 0\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=200, height=200, bg=\"black\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Analyzing..\", font=(\"Helvetica\", 48))\n",
    "        self.classify_btn = tk.Button(self, text=\"Search\", command=self.classify_handwriting)\n",
    "        self.button_clear = tk.Button(self, text=\"Clear\", command=self.clear_all)\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=tk.W)\n",
    "        self.label.grid(row=0, column=1, pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "        # Bindings\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "\n",
    "    def classify_handwriting(self):\n",
    "        self.update()\n",
    "        # Correctly capture the canvas area\n",
    "        x = self.winfo_rootx() + self.canvas.winfo_x()\n",
    "        y = self.winfo_rooty() + self.canvas.winfo_y()\n",
    "        x1 = x + self.canvas.winfo_width()\n",
    "        y1 = y + self.canvas.winfo_height()\n",
    "        print(f\"Capture coordinates: ({x}, {y}, {x1}, {y1})\")  # Debug print\n",
    "        im = ImageGrab.grab(bbox=(x, y, x1, y1))\n",
    "        im.save('captured_image.png')  # Save the captured image for debugging\n",
    "        digit, acc = predict_digit(im)\n",
    "        self.label.configure(text=str(digit) + ', ' + str(int(acc * 100)) + '%')\n",
    "\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r = 8  # Brush size\n",
    "        self.canvas.create_oval(self.x - r, self.y - r, self.x + r, self.y + r, fill='white')\n",
    "\n",
    "app = App()\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c97c6-02c8-48e8-aa93-fd988b1d186c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
